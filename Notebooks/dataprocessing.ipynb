{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "The purpose of this notebook is to process the data and keep it separate from the main analysis and visualization. We will write the code unnecessary for the user to interact with such as functions, import libraries, and processing the data into sheets of data we can interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* content\n",
    "\n",
    "## Notebooks\n",
    "* [Overview Notebook](airpollution.ipynb)\n",
    "* [Processing Notebook](dataprocessing.ipynb)\n",
    "* [Analysis Notebook](data-analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Here are the libraries we are going to use to graph and analyze our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from matplotlib.pyplot import figure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Here are the functions we have created to analyze the datasets we are looking at and graph them to display trends and comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatinate(y):\n",
    "    \n",
    "    path = y\n",
    "    data = glob(path + '*csv')\n",
    "    data.sort()\n",
    "    return pd.concat([pd.read_csv(f) for f in data])\n",
    "\n",
    "def createDataframe(x):\n",
    "\n",
    "    x['ozone_rolling_mean_365'] = x['Ozone_AQI_Value'].rolling(window=365).mean()\n",
    "    x['particle_rolling_mean_365'] = x['PM2.5_AQI_Value'].rolling(window=365).mean()\n",
    "    data = pd.DataFrame({'X' : x['ozone_rolling_mean_365'],\n",
    "                         'Y' : x['particle_rolling_mean_365'],\n",
    "                         'T' : x['Date']})\n",
    "    return data\n",
    "\n",
    "def aqi_plot(x): \n",
    "    \n",
    "    ax = x.plot.line('T',['X', 'Y'], figsize = (15, 10), title = 'Air Quality Trend')\n",
    "    ax.set_xlabel('Time (1985-2020)')\n",
    "    ax.set_ylabel('Air Quality Index (AQI)')\n",
    "    ax.legend(['Ozone (O3)', 'Particulate Matter (PM2.5)'])\n",
    "    ax.grid(True)\n",
    "    \n",
    "def plot_all(x):\n",
    "    \n",
    "    data = x[0]\n",
    "    \n",
    "    for f in range (1, len(x)):\n",
    "        data = pd.merge(data, x[f], how = 'inner', on = 'T')\n",
    "    ax = data.plot.line('T', ['X_x', 'X_y', 'X'], figsize = (40, 10), title = 'Ozone Quality Trend', colormap = 'Paired')\n",
    "    ax.set_xlabel('Time (1985-2020)')\n",
    "    ax.set_ylabel('Average AQI')\n",
    "    ax.legend(['NY-NJ-PA', 'TX', 'MA-NH', 'CA', 'PA-NJ-DE-MD', 'WA', 'MN_WI', 'IL-IN-WI', 'GA', \n",
    "              'MI', 'FL', 'AZ', 'DC-VA-MD-WV', 'CO', 'MO-IL'])\n",
    "    ax.grid(True)\n",
    "    \n",
    "    bx = data.plot.line('T', ['X_y', 'Y_y', 'Y'], figsize = (40, 10), title = 'Particulate Matter Quality Trend', colormap = 'Paired')\n",
    "    bx.set_xlabel('Time (1985-2020)')\n",
    "    bx.set_ylabel('Average AQI')\n",
    "    bx.legend(['NY-NJ-PA', 'TX', 'MA-NH', 'CA', 'PA-NJ-DE-MD', 'WA', 'MN-WI', 'IL-IN-WI', 'GA', \n",
    "              'MI', 'FL', 'AZ', 'DC-VA-MD-WV', 'CO', 'MO-IL'])\n",
    "    bx.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Merging Dataframes For Cleaner Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOzoneDataframe(x):\n",
    "    df = x\n",
    "    df.drop(['PM2.5_AQI_Value'], axis = 1)\n",
    "    df['ozone_rolling_mean_365'] = df['Ozone_AQI_Value'].rolling(window=365).mean()\n",
    "    data = pd.DataFrame({'X' : df['ozone_rolling_mean_365'],\n",
    "                         'T' : df['Date']})\n",
    "    \n",
    "    return data\n",
    "\n",
    "def createParticleDataframe(x):\n",
    "    df = x\n",
    "    df.drop(['Ozone_AQI_Value'], axis = 1)\n",
    "    x['particle_rolling_mean_365'] = x['PM2.5_AQI_Value'].rolling(window=365).mean()\n",
    "    data = pd.DataFrame({'Y' : x['particle_rolling_mean_365'],\n",
    "                         'T' : x['Date']})\n",
    "    return data\n",
    "\n",
    "def merge_plots(x, y):\n",
    "    data = pd.merge(x, y, how = 'inner', on = 'T')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing The Data\n",
    "\n",
    "Here we access the file locations for each metropolitan statistical area and use the methods to create dataframes we can work with so we can plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_nj_pa_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/NewYork-Newark-JerseyCity/')\n",
    "ny_nj_pa = (createDataframe(ny_nj_pa_files))\n",
    "il_in_wi_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Chicago-Naperville-Elgin/')\n",
    "il_in_wi = (createDataframe(il_in_wi_files))\n",
    "tx_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Dallas-FortWorth-Arlington/')\n",
    "tx = (createDataframe(tx_files))\n",
    "ga_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Atlanta-SandySprings-Roswell/')\n",
    "ga = (createDataframe(ga_files))\n",
    "ma_nh_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Boston-Cambridge-Newton/')\n",
    "ma_nh = (createDataframe(ma_nh_files))\n",
    "mi_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Detroit-Warren-Dearborn/')\n",
    "mi = (createDataframe(mi_files))\n",
    "ca_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/LosAngeles-LongBeach-Anaheim/')\n",
    "ca = (createDataframe(ca_files))\n",
    "fl_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Miami-FortLauderdale-WestPalmBeach/')\n",
    "fl = (createDataframe(fl_files))\n",
    "pa_nj_de_md_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Philadelphia-Camden-Wilmington/')\n",
    "pa_nj_de_md = (createDataframe(pa_nj_de_md_files))\n",
    "az_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Phoenix-Mesa-Scottsdale/')\n",
    "az = (createDataframe(az_files))\n",
    "wa_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Seattle-Tacoma-Bellevue/')\n",
    "wa = (createDataframe(wa_files))\n",
    "dc_va_md_wv_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Washington-Arlington-Alexandria/')\n",
    "dc_va_md_wv = (createDataframe(dc_va_md_wv_files))\n",
    "mn_wi_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Minneapolis-St.Paul-Bloomington/')\n",
    "mn_wi = (createDataframe(mn_wi_files))\n",
    "co_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Denver-Aurora-Lakewood/')\n",
    "co = (createDataframe(co_files))\n",
    "mo_il_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/St.Louis/')\n",
    "mo_il = (createDataframe(mo_il_files))\n",
    "\n",
    "areas = [ny_nj_pa, il_in_wi, tx, ga, ma_nh, mi, ca, fl, pa_nj_de_md, az, wa, dc_va_md_wv, mn_wi, co, mo_il]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Merge Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ny_nj_pa_files\n",
    "test2 = createOzoneDataframe(test)\n",
    "test3 = createParticleDataframe(test)\n",
    "test4 = merge_plots(test2, test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
