{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "The purpose of this notebook is to process the data and keep it separate from the main analysis and visualization. We will write the code unnecessary for the user to interact with such as functions, import libraries, and processing the data into sheets of data we can interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* content\n",
    "\n",
    "## Notebooks\n",
    "* [Overview Notebook](airpollution.ipynb)\n",
    "* [Processing Notebook](dataprocessing.ipynb)\n",
    "* [Analysis Notebook](data-analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Here are the libraries we are going to use to graph and analyze our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from matplotlib.pyplot import figure \n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Here are the functions we have created to analyze the datasets we are looking at and graph them to display trends and comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatinate(y):\n",
    "    \n",
    "    path = y\n",
    "    data = glob(path + '*csv')\n",
    "    data.sort()\n",
    "    return pd.concat([pd.read_csv(f) for f in data])\n",
    "\n",
    "def createDataframe(x):\n",
    "\n",
    "    x['ozone_rolling_mean_365'] = x['Ozone_AQI_Value'].rolling(window=365).mean()\n",
    "    x['particle_rolling_mean_365'] = x['PM2.5_AQI_Value'].rolling(window=365).mean()\n",
    "    data = pd.DataFrame({'X' : x['ozone_rolling_mean_365'],\n",
    "                         'Y' : x['particle_rolling_mean_365'],\n",
    "                         'T' : x['Date']})\n",
    "    return data\n",
    "\n",
    "def time_histogram(x):\n",
    "    \n",
    "    data = x.isna()\n",
    "    x['Date'] = pd.to_datetime(x['Date'], format = '%m/%d/%y')\n",
    "    date1 = 0\n",
    "    date2 = 0\n",
    "    timedelta = []\n",
    "    condition = False\n",
    "    \n",
    "    for f in range (len(data)):\n",
    "        if data.iloc[f][2] == True and condition == False:\n",
    "            date1 = x.iloc[f][0]\n",
    "            condition = True\n",
    "        if data.iloc[f][2] == False and condition == True:\n",
    "            date2 = x.iloc[f - 1][0]\n",
    "            condition = False\n",
    "            if date2 - date1 == 0:\n",
    "                timedelta.append(1)\n",
    "            else:\n",
    "                timedelta.append((date2 - date1))\n",
    "    \n",
    "    return timedelta\n",
    "        \n",
    "\n",
    "def aqi_plot(x): \n",
    "    \n",
    "    ax = x.plot.line('T',['X', 'Y'], figsize = (15, 10), title = 'Air Quality Trend')\n",
    "    ax.set_xlabel('Time (1985-2020)')\n",
    "    ax.set_ylabel('Air Quality Index (AQI)')\n",
    "    ax.legend(['Ozone (O3)', 'Particulate Matter (PM2.5)'])\n",
    "    ax.grid(True)\n",
    "    \n",
    "def plot_all(x):\n",
    "    \n",
    "\n",
    "    data = x[0]\n",
    "    \n",
    "    for f in range (1, len(x)):\n",
    "        data = pd.merge(data, x[f], how = 'inner', on = 'T')\n",
    "    ax = data.plot.line('T', ['X_x', 'X_y', 'X'], figsize = (40, 10), title = 'Ozone Quality Trend', colormap = 'Paired')\n",
    "    ax.set_xlabel('Time (1985-2020)')\n",
    "    ax.set_ylabel('Average AQI')\n",
    "    ax.legend(['NY-NJ-PA', 'TX', 'MA-NH', 'CA', 'PA-NJ-DE-MD', 'WA', 'MN_WI', 'IL-IN-WI', 'GA', \n",
    "              'MI', 'FL', 'AZ', 'DC-VA-MD-WV', 'CO', 'MO-IL'])\n",
    "    ax.grid(True)\n",
    "    \n",
    "    bx = data.plot.line('T', ['X_y', 'Y_y', 'Y'], figsize = (40, 10), title = 'Particulate Matter Quality Trend', colormap = 'Paired')\n",
    "    bx.set_xlabel('Time (1985-2020)')\n",
    "    bx.set_ylabel('Average AQI')\n",
    "    bx.legend(['NY-NJ-PA', 'TX', 'MA-NH', 'CA', 'PA-NJ-DE-MD', 'WA', 'MN-WI', 'IL-IN-WI', 'GA', \n",
    "              'MI', 'FL', 'AZ', 'DC-VA-MD-WV', 'CO', 'MO-IL'])\n",
    "    bx.grid(True)\n",
    "\n",
    "def production(x, z):\n",
    "\n",
    "    y = x\n",
    "    goods = ['Gasoline', 'Fuel oils', 'Coal n.e.c', 'Motorized vehicles', 'Transport equipment', 'Machinery'\n",
    "                   , 'Chemical products', 'Newsprint/paper', 'Printed products']\n",
    "\n",
    "    y = y.sort_values(by = ['ID SCTG2', 'Year'], ascending = True)\n",
    "\n",
    "    gasoline_index = [y.loc[y['SCTG2'] == 'Gasoline'].index.values.tolist()]\n",
    "    gasoline = []\n",
    "    for i in range (5):\n",
    "        gasoline.append(x.iat[gasoline_index[0][i], 8])\n",
    "    \n",
    "    fuel_oils_index = [y.loc[y['SCTG2'] == 'Fuel oils'].index.values.tolist()]\n",
    "    fuel_oils = []\n",
    "    for i in range (5):\n",
    "        fuel_oils.append(x.iat[fuel_oils_index[0][i], 8])\n",
    "        \n",
    "    coal_nec_index = [y.loc[y['SCTG2'] == 'Coal-n.e.c.'].index.values.tolist()]\n",
    "    coal_nec = []\n",
    "    for i in range (5):\n",
    "        coal_nec.append(x.iat[coal_nec_index[0][i], 8])\n",
    "\n",
    "    motorized_vehicles_index = [y.loc[y['SCTG2'] == 'Motorized vehicles'].index.values.tolist()]\n",
    "    motorized_vehicles = []\n",
    "    for i in range (5):\n",
    "        motorized_vehicles.append(x.iat[motorized_vehicles_index[0][i], 8])\n",
    "    \n",
    "    transport_equipment_index = [y.loc[y['SCTG2'] == 'Transport equip.'].index.values.tolist()]\n",
    "    transport_equipment = []\n",
    "    for i in range (5):\n",
    "        transport_equipment.append(x.iat[transport_equipment_index[0][i], 8])\n",
    "    \n",
    "    machinery_index = [y.loc[y['SCTG2'] == 'Machinery'].index.values.tolist()]\n",
    "    machinery = []\n",
    "    for i in range (5):\n",
    "        machinery.append(x.iat[machinery_index[0][i], 8])\n",
    "        \n",
    "    \n",
    "    newsprint_paper_index = [y.loc[y['SCTG2'] == 'Newsprint/paper'].index.values.tolist()]\n",
    "    newsprint_paper = []\n",
    "    for i in range (5):\n",
    "        newsprint_paper.append(x.iat[newsprint_paper_index[0][i], 8])\n",
    "    \n",
    "    printed_products_index = [y.loc[y['SCTG2'] == 'Printed prods.'].index.values.tolist()]\n",
    "    printed_products = []\n",
    "    for i in range (5):\n",
    "        printed_products.append(x.iat[printed_products_index[0][i], 8])\n",
    "        \n",
    "    time = ['2012', '2013', '2014', '2015', '2020']\n",
    "         \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #plt.stackplot(time, gasoline, fuel_oils, coal_nec, motorized_vehicles, transport_equipment, machinery,\n",
    "    #            newsprint_paper, printed_products)\n",
    "    \n",
    "    #plt.title(z)\n",
    "    #plt.tight_layout()\n",
    "    #plt.legend(['Gasoline', 'Fuel oils', 'Coal n.e.c', 'Motorized vehicles', 'Transport equipment', 'Machinery'\n",
    "    #           , 'Newsprint/paper', 'Printed products'])\n",
    "    #plt.grid(True)\n",
    "    #plt.show()\n",
    "    \n",
    "    plt.plot(time, gasoline)\n",
    "    plt.plot(time, fuel_oils)\n",
    "    plt.plot(time, coal_nec)\n",
    "    plt.plot(time, motorized_vehicles)\n",
    "    plt.plot(time, transport_equipment)\n",
    "    plt.plot(time, machinery)\n",
    "    plt.plot(time, newsprint_paper)\n",
    "    plt.plot(time, printed_products)\n",
    "    plt.title(z)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Millions of Dollars of Growth')\n",
    "    plt.legend(['Gasoline', 'Fuel oils', 'Coal n.e.c', 'Motorized vehicles', 'Transport equipment', 'Machinery',\n",
    "                'Newsprint/paper', 'Printed products'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Merging Dataframes For Cleaner Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOzoneDataframe(x):\n",
    "    df = x\n",
    "    df.drop(['PM2.5_AQI_Value'], axis = 1)\n",
    "    df['ozone_rolling_mean_365'] = df['Ozone_AQI_Value'].rolling(window=365).mean()\n",
    "    data = pd.DataFrame({'X' : df['ozone_rolling_mean_365'],\n",
    "                         'T' : df['Date']})\n",
    "    \n",
    "    return data\n",
    "\n",
    "def createParticleDataframe(x):\n",
    "    df = x\n",
    "    df.drop(['Ozone_AQI_Value'], axis = 1)\n",
    "    x['particle_rolling_mean_365'] = x['PM2.5_AQI_Value'].rolling(window=365).mean()\n",
    "    data = pd.DataFrame({'Y' : x['particle_rolling_mean_365'],\n",
    "                         'T' : x['Date']})\n",
    "    return data\n",
    "\n",
    "def merge_plots(x, y):\n",
    "    data = pd.merge(x, y, how = 'inner', on = 'T')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing The Data\n",
    "\n",
    "Here we access the file locations for each metropolitan statistical area and use the methods to create dataframes we can work with so we can plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_nj_pa_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/NewYork-Newark-JerseyCity/')\n",
    "ny_nj_pa = (createDataframe(ny_nj_pa_files))\n",
    "ny_nj_pa_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/NY-NJ-PA-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "il_in_wi_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Chicago-Naperville-Elgin/')\n",
    "il_in_wi = (createDataframe(il_in_wi_files))\n",
    "il_in_wi_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/IL-IN-WI-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "tx_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Dallas-FortWorth-Arlington/')\n",
    "tx = (createDataframe(tx_files))\n",
    "tx_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/TX-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "ga_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Atlanta-SandySprings-Roswell/')\n",
    "ga = (createDataframe(ga_files))\n",
    "ga_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/GA-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "ma_nh_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Boston-Cambridge-Newton/')\n",
    "ma_nh = (createDataframe(ma_nh_files))\n",
    "ma_nh_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/MA-NH-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "mi_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Detroit-Warren-Dearborn/')\n",
    "mi = (createDataframe(mi_files))\n",
    "mi_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/MI-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "ca_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/LosAngeles-LongBeach-Anaheim/')\n",
    "ca = (createDataframe(ca_files))\n",
    "ca_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/CA-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "fl_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Miami-FortLauderdale-WestPalmBeach/')\n",
    "fl = (createDataframe(fl_files))\n",
    "fl_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/FL-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "pa_nj_de_md_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Philadelphia-Camden-Wilmington/')\n",
    "pa_nj_de_md = (createDataframe(pa_nj_de_md_files))\n",
    "pa_nj_de_md_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/PA-NJ-DE-MD-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "az_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Phoenix-Mesa-Scottsdale/')\n",
    "az = (createDataframe(az_files))\n",
    "az_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/AZ-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "wa_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Seattle-Tacoma-Bellevue/')\n",
    "wa = (createDataframe(wa_files))\n",
    "wa_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/WA-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "dc_va_md_wv_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Washington-Arlington-Alexandria/')\n",
    "dc_va_md_wv = (createDataframe(dc_va_md_wv_files))\n",
    "dc_va_md_wv_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/DC-VA-MD-WV-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "mn_wi_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Minneapolis-St.Paul-Bloomington/')\n",
    "mn_wi = (createDataframe(mn_wi_files))\n",
    "mn_wi_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/MN-WI-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "co_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Denver-Aurora-Lakewood/')\n",
    "co = (createDataframe(co_files))\n",
    "co_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/CO-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "mo_il_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/St.Louis/')\n",
    "mo_il = (createDataframe(mo_il_files))\n",
    "mo_il_production = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/MO-IL-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "\n",
    "areas = [ny_nj_pa, il_in_wi, tx, ga, ma_nh, mi, ca, fl, pa_nj_de_md, az, wa, dc_va_md_wv, mn_wi, co, mo_il]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Merge Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = mi_files\n",
    "test2 = createOzoneDataframe(test)\n",
    "test3 = createParticleDataframe(test)\n",
    "test4 = merge_plots(test2, test3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timedelta('58 days 00:00:00'),\n",
       " Timedelta('89 days 00:00:00'),\n",
       " Timedelta('89 days 00:00:00'),\n",
       " Timedelta('90 days 00:00:00'),\n",
       " Timedelta('89 days 00:00:00'),\n",
       " Timedelta('30 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('1 days 00:00:00'),\n",
       " Timedelta('2 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('2 days 00:00:00'),\n",
       " Timedelta('10 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00'),\n",
       " Timedelta('0 days 00:00:00')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_histogram(ga_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
