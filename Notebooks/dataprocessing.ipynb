{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "The purpose of this notebook is to process the data and keep it separate from the main analysis and visualization. We will write the code unnecessary for the user to interact with such as functions, import libraries, and processing the data into sheets of data we can interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* content\n",
    "\n",
    "## Notebooks\n",
    "* [Overview Notebook](airpollution.ipynb)\n",
    "* [Processing Notebook](dataprocessing.ipynb)\n",
    "* [Analysis Notebook](data-analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Here are the libraries we are going to use to graph and analyze our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from matplotlib.pyplot import figure \n",
    "import datetime\n",
    "import geopandas\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import json\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import (CDSView, ColorBar, ColumnDataSource,\n",
    "                          CustomJS, CustomJSFilter, \n",
    "                          GeoJSONDataSource, HoverTool,\n",
    "                          LinearColorMapper, Slider)\n",
    "from bokeh.layouts import column, row, widgetbox\n",
    "from bokeh.palettes import brewer\n",
    "from bokeh.plotting import figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Here are the functions we have created to analyze the datasets we are looking at and graph them to display trends and comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatinate(path):\n",
    "    files = glob(path + '*csv')\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    "        df['source_file'] = f.split('/')[-1]\n",
    "        dfs.append(df)\n",
    "    \n",
    "    data = pd.concat(dfs)\n",
    "    data.columns = ['date', 'source_ozone_aqi', 'ozone_aqi',\n",
    "                    'source_pm25_aqi', 'pm25_aqi', 'file']\n",
    "    \n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data = data.sort_values('date').reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "def rolling_mean(df, series_name, z = 30):\n",
    "    s = df[['date', series_name]].dropna()\n",
    "    col = '{}_smoothed'.format(series_name)\n",
    "    s[col] = s[series_name].rolling(window=z).mean()\n",
    "    return df.merge(s[['date', col]], how='left')\n",
    "    return data\n",
    "\n",
    "def missing_time_analysis(df, series_name):\n",
    "    print('\\nAnalyzing missing time series data for \"{}\"'.format(series_name))\n",
    "    s = df[['date', series_name]].dropna()\n",
    "    s['delta_t'] = s['date'].diff()\n",
    "    s['delta_days'] = s['delta_t'].apply(lambda t: t.days)\n",
    "    display(s.head(5))\n",
    "    s.delta_days.hist(bins=50)\n",
    "    plt.title('Time Gaps (days)')\n",
    "    plt.show()\n",
    "    display(s['delta_days'].describe())\n",
    "    display(s[s.delta_days > 5]) # show any gaps larger than 5 days\n",
    "    display(s[s['delta_days'] > 5].groupby('delta_days').size())\n",
    "        \n",
    "\n",
    "def aqi_plot(x, y, z): \n",
    "    \n",
    "    temp = ['7/1/1985', '7/1/1986', '7/1/1987', '7/1/1988', '7/1/1989', '7/1/1990', '7/1/1991', '7/1/1992',\n",
    "        '7/1/1993', '7/1/1994', '7/1/1995', '7/1/1996', '7/1/1997', '7/1/1998', '7/1/1999', '7/1/2000',\n",
    "        '7/1/2001', '7/1/2002', '7/1/2003', '7/1/2004', '7/1/2005', '7/1/2006', '7/1/2007', '7/1/2008',\n",
    "        '7/1/2009', '7/1/2010', '7/1/2011', '7/1/2012', '7/1/2013', '7/1/2014', '7/1/2015', '7/1/2016',\n",
    "        '7/1/2017', '7/1/2018', '7/1/2019', '7/1/2020']\n",
    "\n",
    "    x['date'] = pd.to_datetime(x['date'])\n",
    "    y['date'] = pd.to_datetime(temp)\n",
    "    data = pd.merge(x, y, how = 'left', on = 'date')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16, 10))\n",
    "    s = data[['date', 'Annual Ozone']].dropna()\n",
    "    t = data[['date', 'Annual PM2.5']].dropna()\n",
    "    ax.plot(data['date'], data['ozone_aqi_smoothed'], alpha = 0.3)\n",
    "    ax.plot(data['date'], data['pm25_aqi_smoothed'], alpha = 0.3)\n",
    "    ax.plot(s['date'], s['Annual Ozone'])\n",
    "    ax.plot(t['date'], t['Annual PM2.5'])\n",
    "    \n",
    "    ax.set_title(z + ' Air Quality Trend', fontsize=18)\n",
    "    ax.set_xlabel('Time (1985-2020)', fontsize=14)\n",
    "    ax.set_ylabel('Average AQI', fontsize=14)\n",
    "    ax.legend(['Seasonal Ozone', 'Seasonal PM2.5', 'Annual Ozone', 'Annual PM2.5'], prop={'size': 14})\n",
    "    ax.grid()\n",
    "\n",
    "def year_plot(x, y):\n",
    "    data = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Areas/' + x + '/2020-' + y + '.csv')\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data['ozone_aqi'] = data['Ozone_AQI_Value'].rolling(window=7).mean()\n",
    "    data['pm25_aqi'] = data['PM2.5_AQI_Value'].rolling(window=7).mean()\n",
    "    ozone = data[['Date', 'ozone_aqi']].dropna()\n",
    "    particle = data[['Date', 'pm25_aqi']].dropna()\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "    ax.plot(ozone['Date'], ozone['ozone_aqi'])\n",
    "    ax.plot(particle['Date'], particle['pm25_aqi'])\n",
    "    ax.set_title(y + ' 2020 AQI Trend', fontsize = 18)\n",
    "    ax.set_xlabel('Time', fontsize = 14)\n",
    "    ax.set_ylabel('AQI', fontsize = 14)\n",
    "    ax.legend(['Ozone', 'PM2.5'])\n",
    "    ax.grid()\n",
    "\n",
    "    \n",
    "def plot_all(x):\n",
    "    \n",
    "\n",
    "    data = x[0]\n",
    "    \n",
    "   \n",
    "    for f in range (1, len(x)):\n",
    "        data = pd.merge(data, x[f], how = 'inner', on = 'date')\n",
    "    ax = data.plot.line('date', ['ozone_aqi_smoothed_x', \n",
    "                                 'ozone_aqi_smoothed_y', 'ozone_aqi_smoothed'], figsize = (20, 10), title = 'Ozone Quality Trend', colormap = 'Paired')\n",
    "    ax.set_xlabel('Time (1985-2020)')\n",
    "    ax.set_ylabel('Average AQI')\n",
    "    ax.legend(['NY-NJ-PA', 'TX', 'MA-NH', 'CA', 'PA-NJ-DE-MD', 'WA', 'MN-WI', 'IL-IN-WI', 'GA', \n",
    "              'MI', 'FL', 'AZ', 'DC-VA-MD-WV', 'CO', 'MO-IL'])\n",
    "    ax.grid(True)\n",
    "    \n",
    "    bx = data.plot.line('date', ['pm25_aqi_smoothed_x',\n",
    "                                 'pm25_aqi_smoothed_y', 'pm25_aqi_smoothed'], figsize = (20, 10), title = 'Particulate Matter Quality Trend', colormap = 'Paired')\n",
    "    bx.set_xlabel('Time (1985-2020)')\n",
    "    bx.set_ylabel('Average AQI')\n",
    "    bx.legend(['NY-NJ-PA', 'TX', 'MA-NH', 'CA', 'PA-NJ-DE-MD', 'WA', 'MN-WI', 'IL-IN-WI', 'GA', \n",
    "              'MI', 'FL', 'AZ', 'DC-VA-MD-WV', 'CO', 'MO-IL'])\n",
    "    bx.grid(True)\n",
    "\n",
    "def production_data(x, z, annual):\n",
    "\n",
    "    y = x\n",
    "    file = [z, z, z, z, z]\n",
    "\n",
    "    y = y.sort_values(by = ['ID SCTG2', 'Year'], ascending = True)\n",
    "\n",
    "    gasoline_index = [y.loc[y['SCTG2'] == 'Gasoline'].index.values.tolist()]\n",
    "    gasoline = []\n",
    "    for i in range (5):\n",
    "        gasoline.append(x.iat[gasoline_index[0][i], 4])\n",
    "    \n",
    "    fuel_oils_index = [y.loc[y['SCTG2'] == 'Fuel oils'].index.values.tolist()]\n",
    "    fuel_oils = []\n",
    "    for i in range (5):\n",
    "        fuel_oils.append(x.iat[fuel_oils_index[0][i], 4])\n",
    "        \n",
    "    coal_nec_index = [y.loc[y['SCTG2'] == 'Coal-n.e.c.'].index.values.tolist()]\n",
    "    coal_nec = []\n",
    "    for i in range (5):\n",
    "        coal_nec.append(x.iat[coal_nec_index[0][i], 4])\n",
    "\n",
    "    motorized_vehicles_index = [y.loc[y['SCTG2'] == 'Motorized vehicles'].index.values.tolist()]\n",
    "    motorized_vehicles = []\n",
    "    for i in range (5):\n",
    "        motorized_vehicles.append(x.iat[motorized_vehicles_index[0][i], 4])\n",
    "    \n",
    "    transport_equipment_index = [y.loc[y['SCTG2'] == 'Transport equip.'].index.values.tolist()]\n",
    "    transport_equipment = []\n",
    "    for i in range (5):\n",
    "        transport_equipment.append(x.iat[transport_equipment_index[0][i], 4])\n",
    "    \n",
    "    machinery_index = [y.loc[y['SCTG2'] == 'Machinery'].index.values.tolist()]\n",
    "    machinery = []\n",
    "    for i in range (5):\n",
    "        machinery.append(x.iat[machinery_index[0][i], 4])\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    time = ['2012', '2013', '2014', '2015', '2020']\n",
    "    \n",
    "    df = pd.DataFrame({'date' : time,\n",
    "                       'Gasoline' : gasoline, \n",
    "                       'Fuel oils' : fuel_oils,\n",
    "                       'Coal n.e.c.' : coal_nec,\n",
    "                       'Motorized vehicles' : motorized_vehicles,\n",
    "                       'Transport equipment' : transport_equipment,\n",
    "                       'Machinery' : machinery,\n",
    "                       'Area' : z})\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    df = pd.merge(df, annual, how = 'left', on = 'date')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def production_graph(x, z):\n",
    "    x['date'] = x['date'].dt.strftime('%Y')\n",
    "    bx = x.plot.bar('date', ['Gasoline', 'Fuel oils', 'Coal n.e.c.', 'Motorized vehicles', \n",
    "                             'Transport equipment', 'Machinery'], figsize = (15, 10), title = z, ylim = (0, 300000))\n",
    "    bx.set_xlabel('Year')\n",
    "    bx.set_ylabel('Millions of Dollars')\n",
    "    bx.grid(True)\n",
    "    bx.legend(['Gasoline', 'Fuel oils', 'Coal n.e.c', 'Motorized vehicles', 'Transport equipment', 'Machinery'])\n",
    "    \n",
    "def msa_drop(x):\n",
    "    data = x\n",
    "    data.drop(data[(data['NAME'] != 'New York-Newark-Jersey City, NY-NJ-PA') &\n",
    "                 (data['NAME'] != 'Los Angeles-Long Beach-Anaheim, CA') &\n",
    "                 (data['NAME'] != 'Chicago-Naperville-Elgin, IL-IN-WI') &\n",
    "                 (data['NAME'] != 'Dallas-Fort Worth-Arlington, TX') &\n",
    "                 (data['NAME'] != 'Washington-Arlington-Alexandria, DC-VA-MD-WV') &\n",
    "                 (data['NAME'] != 'Miami-Fort Lauderdale-Pompano Beach, FL') &\n",
    "                 (data['NAME'] != 'Philadelphia-Camden-Wilmington, PA-NJ-DE-MD') &\n",
    "                 (data['NAME'] != 'Atlanta-Sandy Springs-Alpharetta, GA') &\n",
    "                 (data['NAME'] != 'Phoenix-Mesa-Chandler, AZ') &\n",
    "                 (data['NAME'] != 'Boston-Cambridge-Newton, MA-NH') &\n",
    "                 (data['NAME'] != 'Detroit-Warren-Dearborn, MI') &\n",
    "                 (data['NAME'] != 'Seattle-Tacoma-Bellevue, WA') &\n",
    "                 (data['NAME'] != 'Minneapolis-St. Paul-Bloomington, MN-WI') &\n",
    "                 (data['NAME'] != 'Denver-Aurora-Lakewood, CO') &\n",
    "                 (data['NAME'] != 'St. Louis, MO-IL')].index, inplace=True)\n",
    "    return data\n",
    "\n",
    "def aqi_annual_average(area, abbr):\n",
    "    \n",
    "    year = []\n",
    "    ozone_aqi = []\n",
    "    pm25_aqi = []\n",
    "    for i in range(1985, 2021):\n",
    "        file = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Areas/' + area + '/' + str(i) + '-' + abbr + '.csv')\n",
    "        year.append(str(i))\n",
    "        ozone_aqi.append([file['Ozone_AQI_Value'].mean()])\n",
    "        pm25_aqi.append([file['PM2.5_AQI_Value'].mean()])\n",
    "    data = pd.DataFrame({'date' : year,\n",
    "                         'Annual Ozone' : ozone_aqi,\n",
    "                         'Annual PM2.5' : pm25_aqi})\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['Annual Ozone'] = data['Annual Ozone'].str[0]\n",
    "    data['Annual PM2.5'] = data['Annual PM2.5'].str[0]\n",
    "    return data\n",
    "\n",
    "def correlation(df, title):    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    corrMatrix = df.corr()\n",
    "    #matrix = np.triu(df.corr())\n",
    "    sns.heatmap(corrMatrix, annot=True, center = 0, fmt = '.1g', cmap = 'seismic', linewidths = 1, \n",
    "                linecolor = 'black', square = True)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def annual_list(x, y):\n",
    "    ozone = []\n",
    "    pm25 = []\n",
    "    for f in range (len(x)):\n",
    "        ozone.append(x[f].iat[27, 1])\n",
    "        ozone.append(x[f].iat[28, 1])\n",
    "        ozone.append(x[f].iat[29, 1])\n",
    "        ozone.append(x[f].iat[30, 1])\n",
    "        ozone.append(x[f].iat[35, 1])\n",
    "        \n",
    "        pm25.append(x[f].iat[27, 2])\n",
    "        pm25.append(x[f].iat[28, 2])\n",
    "        pm25.append(x[f].iat[29, 2])\n",
    "        pm25.append(x[f].iat[30, 2])\n",
    "        pm25.append(x[f].iat[35, 2])\n",
    "        \n",
    "    df = pd.DataFrame({'Year' : y['date'],\n",
    "                       'O3' : ozone,\n",
    "                       'PM2.5' : pm25})\n",
    "    return df\n",
    "\n",
    "def mobility(x, y, z):\n",
    "    retail_index = x.loc[x['Type'] == 'Retail and Recreation'].index.values.tolist()\n",
    "    workplace_index = x.loc[x['Type'] == 'Workplaces'].index.values.tolist()\n",
    "    transit_index = x.loc[x['Type'] == 'Transit Stations'].index.values.tolist()\n",
    "    grocery_index = x.loc[x['Type'] == 'Grocery and Pharmacy'].index.values.tolist()\n",
    "    \n",
    "    aqi = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Areas/' + y + '/2020-' + z + '.csv')\n",
    "    aqi['Ozone_AQI_Value'] = aqi['Ozone_AQI_Value'].rolling(window=7).mean()\n",
    "    aqi['PM2.5_AQI_Value'] = aqi['PM2.5_AQI_Value'].rolling(window=7).mean()\n",
    "    \n",
    "    time = []\n",
    "    retail = []\n",
    "    workplace = []\n",
    "    transit = []\n",
    "    grocery = []\n",
    "    \n",
    "    for i in range(175):\n",
    "        time.append(x.iloc[i, 1])\n",
    "    \n",
    "    for i in range(len(retail_index)):\n",
    "        retail.append(x.iloc[retail_index[i], 3])\n",
    "        \n",
    "    for i in range(len(workplace_index)):\n",
    "        workplace.append(x.iloc[workplace_index[i], 3])\n",
    "        \n",
    "    for i in range(len(transit_index)):\n",
    "        transit.append(x.iloc[transit_index[i], 3])\n",
    "        \n",
    "    for i in range(len(grocery_index)):\n",
    "        grocery.append(x.iloc[grocery_index[i], 3])\n",
    "    \n",
    "    data = pd.DataFrame({'Date' : time,\n",
    "                         'Retail and Recreation' : retail,\n",
    "                         'Workplace' : workplace,\n",
    "                         'Transit' : transit,\n",
    "                         'Grocery' : grocery})\n",
    "    data['Retail and Recreation'] = data['Retail and Recreation'].rolling(window=7).mean()\n",
    "    data['Workplace'] = data['Workplace'].rolling(window=7).mean()\n",
    "    data['Transit'] = data['Transit'].rolling(window=7).mean()\n",
    "    data['Grocery'] = data['Grocery'].rolling(window=7).mean()\n",
    "    \n",
    "    merge = pd.merge(data, aqi, how = 'inner', on = 'Date')\n",
    "    merge['Date'] = pd.to_datetime(merge['Date'])\n",
    "    return merge\n",
    "\n",
    "def plot_mobility(x):\n",
    "    fig, ax = plt.subplots(figsize = (15, 10))\n",
    "    ax.plot(x['Date'], x['Ozone AQI'])\n",
    "    ax.plot(x['Date'], x['PM2.5 AQI'])\n",
    "    ax.plot(x['Date'], x['Retail and Recreation'])\n",
    "    ax.plot(x['Date'], x['Workplace'])\n",
    "    ax.plot(x['Date'], x['Transit'])\n",
    "    ax.plot(x['Date'], x['Grocery'])\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Number in AQI and Commute Changes')\n",
    "    ax.legend(['Ozone AQI', 'PM2.5 AQI', 'Retail and Recreation', 'Workplace', 'Transit', 'Grocery'])\n",
    "    ax.grid()\n",
    "\n",
    "def plot_commuting(df, title):\n",
    "    fig = plt.figure(figsize=(5,4))\n",
    "    x = df['Date']\n",
    "    y1 = df['Workplace']\n",
    "    y2 = df['Retail and Recreation']\n",
    "    y3 = df['Transit']\n",
    "    y4 = df['Grocery']\n",
    "    y5 = df['PM2.5_AQI_Value']\n",
    "    plt.scatter(x, y1, label='Workplace Commuting')\n",
    "    plt.scatter(x, y2, label= 'Retail and Recreation')\n",
    "    plt.scatter(x, y3, label = 'Transit')\n",
    "    plt.scatter(x, y4, label = 'Grocery')\n",
    "    plt.scatter(x, y5, label='PM2.5')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=3)\n",
    "    plt.show()\n",
    "\n",
    "def gdp_production(metro, aqi):\n",
    "    gdp_time = ['2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n",
    "    aqi_time = ['1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
    "                '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013','2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
    "    df = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/Metro-Production-GDP.csv')\n",
    "    df = df.replace({'(D)' : None})\n",
    "    area = df.loc[df['GeoName'] == metro]\n",
    "    \n",
    "    mining = []\n",
    "    utilities = []\n",
    "    construction = []\n",
    "    manufacturing = []\n",
    "    transportation = []\n",
    "    natural = []\n",
    "    \n",
    "    gdp_mining = area.loc[area['Description'] == '    Mining, quarrying, and oil and gas extraction']\n",
    "    gdp_utilities = area.loc[area['Description'] == '    Utilities']\n",
    "    gdp_construction = area.loc[area['Description'] == '    Construction']\n",
    "    gdp_manufacturing = area.loc[area['Description'] == '    Manufacturing']\n",
    "    gdp_transportation = area.loc[area['Description'] == '    Transportation and warehousing']\n",
    "    gdp_natural = area.loc[area['Description'] == 'Natural resources and mining']\n",
    "    \n",
    "    for i in range(4, 22):\n",
    "        \n",
    "        if gdp_mining.iloc[0, i] != None:\n",
    "            mining.append((int)(gdp_mining.iloc[0, i]))\n",
    "        else:\n",
    "            mining.append(None)\n",
    "        \n",
    "        if gdp_utilities.iloc[0, i] != None:\n",
    "            utilities.append((int)(gdp_utilities.iloc[0, i]))\n",
    "        else:\n",
    "            utilities.append(None)\n",
    "            \n",
    "        if gdp_construction.iloc[0, i] != None:\n",
    "            construction.append((int)(gdp_construction.iloc[0, i]))\n",
    "        else:\n",
    "            construction.append(None)\n",
    "        \n",
    "        if gdp_manufacturing.iloc[0, i] != None:\n",
    "            manufacturing.append((int)(gdp_manufacturing.iloc[0, i]))\n",
    "        else:\n",
    "            manufacturing.append(None)\n",
    "        \n",
    "        if gdp_transportation.iloc[0, i] != None:\n",
    "            transportation.append((int)(gdp_transportation.iloc[0, i]))\n",
    "        else:\n",
    "            transportation.append(None)\n",
    "        \n",
    "        if gdp_natural.iloc[0, i] != None:\n",
    "            natural.append((int)(gdp_natural.iloc[0, i]))\n",
    "        else:\n",
    "            natural.append(None)\n",
    "            \n",
    "    data = pd.DataFrame({'date' : gdp_time,\n",
    "                         'Mining, quarrying, oil and gas extraction' : mining,\n",
    "                            'Utilities' : utilities,\n",
    "                            'Construction' : construction,\n",
    "                            'Manufacturing' : manufacturing,\n",
    "                            'Transportation and warehousing' : transportation,\n",
    "                            'Natural resources and mining' : natural})\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    aqi['date'] = aqi_time\n",
    "    aqi['date'] = pd.to_datetime(aqi['date'])\n",
    "    data = pd.merge(data, aqi, how = 'left', on = 'date')\n",
    "\n",
    "    return data\n",
    "\n",
    "def gdp_plot(x, y):\n",
    "    fig, ax1 = plt.subplots(figsize=(16, 10))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(x['date'], x['Mining, quarrying, oil and gas extraction'], alpha = 0.4)\n",
    "    ax1.plot(x['date'], x['Utilities'], alpha = 0.4)\n",
    "    ax1.plot(x['date'], x['Construction'], alpha = 0.4)\n",
    "    ax1.plot(x['date'], x['Manufacturing'], alpha = 0.4)\n",
    "    ax1.plot(x['date'], x['Natural resources and mining'], alpha = 0.4)\n",
    "    ax1.plot(x['date'], x['Transportation and warehousing'], alpha = 0.4)\n",
    "    ax2.plot(x['date'], x['Annual Ozone'], '--', linewidth = 5)\n",
    "    ax2.plot(x['date'], x['Annual PM2.5'], '--', linewidth = 5)\n",
    "    ax2.grid(b=False)\n",
    "    \n",
    "    ax1.legend(['Mining, quarrying, oil and gas extraction', 'Utilities', 'Construction', 'Manufacturing', \n",
    "               'Natural resources and mining', 'Transportation and warehousing'], loc = 'upper left') \n",
    "    ax2.legend(['Annual Ozone', 'Annual PM2.5'], loc = 'upper right')\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('GDP (In Hundreds of Millions of Dollars)')\n",
    "    ax2.set_ylabel('AQI')\n",
    "    ax1.set_title(y)\n",
    "    ax1.grid()\n",
    "\n",
    "def mobility_plot(x, y):\n",
    "    \n",
    "    x['Smoothed O3'] = x['Ozone_AQI_Value'].rolling(window=7).mean()\n",
    "    x['Smoothed PM2.5'] = x['PM2.5_AQI_Value'].rolling(window=7).mean()\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(16, 10))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(x['Date'], x['Grocery'], alpha = 0.4)\n",
    "    ax1.plot(x['Date'], x['Transit'], alpha = 0.4)\n",
    "    ax1.plot(x['Date'], x['Workplace'], alpha = 0.4)\n",
    "    ax1.plot(x['Date'], x['Retail and Recreation'], alpha = 0.4)\n",
    "    ax2.plot(x['Date'], x['Smoothed O3'], '--', linewidth = 5)\n",
    "    ax2.plot(x['Date'], x['Smoothed PM2.5'], '--', linewidth = 5)\n",
    "    ax2.grid(b=False)\n",
    "    \n",
    "    ax1.legend(['Grocery', 'Transit', 'Workplace', 'Retail and Recreation'], loc = 'upper left') \n",
    "    ax2.legend(['Ozone', 'PM2.5'], loc = 'upper right')\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Percent Change From Baseline Traveling')\n",
    "    ax2.set_ylabel('AQI')\n",
    "    ax1.set_title(y)\n",
    "    ax1.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_year_aqi(msa, index, p, year, us):\n",
    "    msa_names = ['GA', 'MA-NH', 'TX', 'CO', 'MI', 'IL-IN-WI', 'CA', 'FL', \n",
    "             'MN-WI', 'NY-NJ-PA','PA-NJ-DE-MD','AZ', 'MO-IL', 'WA', 'DC-VA-MD-WV']\n",
    "    msa['NAMELSAD'] = msa_names\n",
    "    \n",
    "    aqi = [ga_annual.iloc[index, p], ma_nh_annual.iloc[index, p], tx_annual.iloc[index, p], \n",
    "               co_annual.iloc[index, p], mi_annual.iloc[index, p], il_in_wi_annual.iloc[index, p], \n",
    "               ca_annual.iloc[index, p], fl_annual.iloc[index, p], mn_wi_annual.iloc[index, p], \n",
    "               ny_nj_pa_annual.iloc[index, p], pa_nj_de_md_annual.iloc[index, p], \n",
    "               az_annual.iloc[index, p], mo_il_annual.iloc[index, p], wa_annual.iloc[index, p], \n",
    "               dc_va_md_wv_annual.iloc[index, p]]  \n",
    "    temp = pd.DataFrame({'NAMELSAD' : msa_names,\n",
    "                          year : aqi})\n",
    "    display = pd.merge(msa, temp, how = 'left', on = 'NAMELSAD')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_aspect('equal')\n",
    "    fig.set_figheight(20)\n",
    "    fig.set_figwidth(20)\n",
    "    ax.set_ylim([23, 50])\n",
    "    ax.set_xlim([-130,-60])\n",
    "    ax.set_title(year + ' MSA Air Quality', fontsize = 20)\n",
    "    ax.set_axis_off()\n",
    "    us.plot(ax=ax, color='white', edgecolor='k')\n",
    "    #labels = ['Good', 'Moderate', 'Unhealthy For Sensitive Groups', 'Unhealthy', 'Very Unhealthy']\n",
    "    divider = make_axes_locatable(ax)\n",
    "    display.plot(ax = ax, alpha = 0.3, edgecolor = 'k', column = year, legend = True,\n",
    "                       cax = divider.append_axes(\"right\", size=\"6%\", pad=0.1))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(msa, us):\n",
    "    year = ''\n",
    "    while(year != 'STOP'):\n",
    "        year = input('Enter a year from 1985-2020 to see the AQI, or type STOP to stop the simulation: ' )\n",
    "        if year != 'STOP':\n",
    "            pollutant = input('Enter O3 or PM2.5 to see the year AQI for that pollutant: ')\n",
    "            if year == '1985' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 0, 1, year, us)\n",
    "            elif year == '1985' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 0, 2, year, us)\n",
    "            elif year == '1986' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 1, 1, year, us)\n",
    "            elif year == '1986' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 1, 2, year, us)\n",
    "            elif year == '1987' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 2, 1, year, us)\n",
    "            elif year == '1987' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 2, 2, year, us)\n",
    "            elif year == '1988' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 3, 1, year, us)\n",
    "            elif year == '1988' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 3, 2, year, us)\n",
    "            elif year == '1989' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 4, 1, year, us)\n",
    "            elif year == '1989' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 4, 2, year, us)\n",
    "            elif year == '1990' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 5, 1, year, us)\n",
    "            elif year == '1990' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 5, 2, year, us)\n",
    "            elif year == '1991' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 6, 1, year, us)\n",
    "            elif year == '1991' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 6, 2, year, us)\n",
    "            elif year == '1992' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 7, 1, year, us)\n",
    "            elif year == '1992' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 7, 2, year, us)\n",
    "            elif year == '1993' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 8, 1, year, us)\n",
    "            elif year == '1993' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 8, 2, year, us)\n",
    "            elif year == '1994' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 9, 1, year, us)\n",
    "            elif year == '1994' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 9, 2, year, us)\n",
    "            elif year == '1995' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 10, 1, year, us)\n",
    "            elif year == '1995' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 10, 2, year, us)\n",
    "            elif year == '1996' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 11, 1, year, us)\n",
    "            elif year == '1996' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 11, 2, year, us)\n",
    "            elif year == '1997' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 12, 1, year, us)\n",
    "            elif year == '1997' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 12, 2, year, us)\n",
    "            elif year == '1998' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 13, 1, year, us)\n",
    "            elif year == '1998' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 13, 2, year, us)\n",
    "            elif year == '1999' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 14, 1, year, us)\n",
    "            elif year == '1999' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 14, 2, year, us)\n",
    "            elif year == '2000' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 15, 1, year, us)\n",
    "            elif year == '2000' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 15, 2, year, us)\n",
    "            elif year == '2001' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 16, 1, year, us)\n",
    "            elif year == '2001' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 16, 2, year, us)\n",
    "            elif year == '2002' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 17, 1, year, us)\n",
    "            elif year == '2002' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 17, 2, year, us)\n",
    "            elif year == '2003' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 18, 1, year, us)\n",
    "            elif year == '2003' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 18, 2, year, us)\n",
    "            elif year == '2004' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 19, 1, year, us)\n",
    "            elif year == '2004' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 19, 2, year, us)\n",
    "            elif year == '2005' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 20, 1, year, us)\n",
    "            elif year == '2005' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 20, 2, year, us)\n",
    "            elif year == '2006' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 21, 1, year, us)\n",
    "            elif year == '2006' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 21, 2, year, us)\n",
    "            elif year == '2007' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 22, 1, year, us)\n",
    "            elif year == '2007' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 22, 2, year, us)\n",
    "            elif year == '2008' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 23, 1, year, us)\n",
    "            elif year == '2008' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 23, 2, year, us)\n",
    "            elif year == '2009' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 24, 1, year, us)\n",
    "            elif year == '2009' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 24, 2, year, us)\n",
    "            elif year == '2010' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 25, 1, year, us)\n",
    "            elif year == '2010' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 25, 2, year, us)\n",
    "            elif year == '2011' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 26, 1, year, us)\n",
    "            elif year == '2011' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 26, 2, year, us)\n",
    "            elif year == '2012' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 27, 1, year, us)\n",
    "            elif year == '2012' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 27, 2, year, us)\n",
    "            elif year == '2013' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 28, 1, year, us)\n",
    "            elif year == '2013' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 28, 2, year, us)\n",
    "            elif year == '2014' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 29, 1, year, us)\n",
    "            elif year == '2014' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 29, 2, year, us)\n",
    "            elif year == '2015' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 30, 1, year, us)\n",
    "            elif year == '2015' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 30, 2, year, us)\n",
    "            elif year == '2016' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 31, 1, year, us)\n",
    "            elif year == '2016' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 31, 2, year, us)\n",
    "            elif year == '2017' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 32, 1, year, us)\n",
    "            elif year == '2017' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 32, 2, year, us)\n",
    "            elif year == '2018' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 33, 1, year, us)\n",
    "            elif year == '2018' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 33, 2, year, us)\n",
    "            elif year == '2019' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 34, 1, year, us)\n",
    "            elif year == '2019' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 34, 2, year, us)\n",
    "            elif year == '2020' and pollutant == 'O3':\n",
    "                plot_year_aqi(msa, 35, 1, year, us)\n",
    "            elif year == '2020' and pollutant == 'PM2.5':\n",
    "                plot_year_aqi(msa, 35, 2, year, us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_simulation(x):\n",
    "    state = ''\n",
    "    state_initials = ['ME', 'MA', 'NH', 'NJ', 'NY', 'PA', 'IL', 'IN', 'MI', 'WI', 'MN', 'MO', 'DE', 'FL',\n",
    "                  'GA', 'MD', 'VA', 'WV', 'TX', 'AZ', 'CO', 'CA', 'WA']\n",
    "    while(state != 'STOP'):\n",
    "        print('List of States: ME, MA, NH, NJ, NY, PA, IL, IN, MI, WI, MN, MO, DE, FL, GA, MD, VA, WV, TX, AZ, CO, CA, WA')\n",
    "        state = input('Enter a state from the list above to see the energy used, or type STOP to stop the simulation. ')\n",
    "        if state != 'STOP':\n",
    "            fig, ax = plt.subplots(figsize = (16, 10))\n",
    "            ax.plot(x['Year'], x['Coal-' + state])\n",
    "            ax.plot(x['Year'], x['Natural-Gas-' + state])\n",
    "            ax.plot(x['Year'], x['Nuclear-' + state])\n",
    "            ax.plot(x['Year'], x['Hydroelectric-' + state])\n",
    "            ax.plot(x['Year'], x['Wind-' + state])\n",
    "            ax.plot(x['Year'], x['Solar-' + state])\n",
    "            ax.set_title(state + ' Energy Output Trend', fontsize=18)\n",
    "            ax.set_xlabel('Year', fontsize=14)\n",
    "            ax.set_ylabel('Energy Output (thousands of megawatt hours)', fontsize=14)\n",
    "            ax.legend(['Coal', 'Natural Gas', 'Nuclear', 'Hydroelectric', 'Wind', 'Solar'], prop={'size': 14})\n",
    "            ax.grid()\n",
    "            plt.show()\n",
    "def energy(x, y, state):\n",
    "    energy_time = ['7/1/2001', '7/1/2002', '7/1/2003', '7/1/2004', '7/1/2005', '7/1/2006', '7/1/2007', '7/1/2008',\n",
    "        '7/1/2009', '7/1/2010', '7/1/2011', '7/1/2012', '7/1/2013', '7/1/2014', '7/1/2015', '7/1/2016',\n",
    "        '7/1/2017', '7/1/2018', '7/1/2019']\n",
    "    annual_time = ['7/1/1985', '7/1/1986', '7/1/1987', '7/1/1988', '7/1/1989', '7/1/1990', '7/1/1991', '7/1/1992',\n",
    "        '7/1/1993', '7/1/1994', '7/1/1995', '7/1/1996', '7/1/1997', '7/1/1998', '7/1/1999', '7/1/2000',\n",
    "        '7/1/2001', '7/1/2002', '7/1/2003', '7/1/2004', '7/1/2005', '7/1/2006', '7/1/2007', '7/1/2008',\n",
    "        '7/1/2009', '7/1/2010', '7/1/2011', '7/1/2012', '7/1/2013', '7/1/2014', '7/1/2015', '7/1/2016',\n",
    "        '7/1/2017', '7/1/2018', '7/1/2019', '7/1/2020']\n",
    "    \n",
    "    energy = pd.DataFrame({'date' : energy_time,\n",
    "                           'Coal' : x['Coal-' + state],\n",
    "                           'Natural Gas' : x['Natural-Gas-' + state],\n",
    "                           'Nuclear' : x['Nuclear-' + state],\n",
    "                           'Hydroelectric' : x['Hydroelectric-' + state],\n",
    "                           'Wind' : x['Wind-' + state],\n",
    "                           'Solar' : x['Solar-' + state]})\n",
    "    energy['date'] = pd.to_datetime(energy['date'])\n",
    "    energy = energy.sort_values('date', ascending = True)\n",
    "    \n",
    "    \n",
    "    y['date'] = pd.to_datetime(annual_time)\n",
    "    energy = pd.merge(energy, y, how = 'left', on = 'date')\n",
    "    \n",
    "    coal_percent = []\n",
    "    natural_gas_percent = []\n",
    "    nuclear_percent = []\n",
    "    hydroelectric_percent = []\n",
    "    wind_percent = []\n",
    "    solar_percent = []\n",
    "    \n",
    "    energy = energy.fillna(0)\n",
    "    \n",
    "    for i in range(19):\n",
    "        \n",
    "        coal_percent.append(energy.iloc[i, 1] / (energy.iloc[i, 1] + \n",
    "                                                energy.iloc[i, 2] + \n",
    "                                                energy.iloc[i, 3] + \n",
    "                                                energy.iloc[i, 4] + \n",
    "                                                energy.iloc[i, 5] +\n",
    "                                                energy.iloc[i, 6]))\n",
    "        natural_gas_percent.append(energy.iloc[i, 2] / (energy.iloc[i, 1] + \n",
    "                                                energy.iloc[i, 2] + \n",
    "                                                energy.iloc[i, 3] + \n",
    "                                                energy.iloc[i, 4] + \n",
    "                                                energy.iloc[i, 5] +\n",
    "                                                energy.iloc[i, 6]))\n",
    "        nuclear_percent.append(energy.iloc[i, 3] / (energy.iloc[i, 1] + \n",
    "                                                energy.iloc[i, 2] + \n",
    "                                                energy.iloc[i, 3] + \n",
    "                                                energy.iloc[i, 4] + \n",
    "                                                energy.iloc[i, 5] +\n",
    "                                                energy.iloc[i, 6]))\n",
    "        hydroelectric_percent.append(energy.iloc[i, 4] / (energy.iloc[i, 1] + \n",
    "                                                energy.iloc[i, 2] + \n",
    "                                                energy.iloc[i, 3] + \n",
    "                                                energy.iloc[i, 4] + \n",
    "                                                energy.iloc[i, 5] +\n",
    "                                                energy.iloc[i, 6]))\n",
    "        wind_percent.append(energy.iloc[i, 5] / (energy.iloc[i, 1] + \n",
    "                                                energy.iloc[i, 2] + \n",
    "                                                energy.iloc[i, 3] + \n",
    "                                                energy.iloc[i, 4] + \n",
    "                                                energy.iloc[i, 5] +\n",
    "                                                energy.iloc[i, 6]))\n",
    "        solar_percent.append(energy.iloc[i, 6] / (energy.iloc[i, 1] + \n",
    "                                                energy.iloc[i, 2] + \n",
    "                                                energy.iloc[i, 3] + \n",
    "                                                energy.iloc[i, 4] + \n",
    "                                                energy.iloc[i, 5] +\n",
    "                                                energy.iloc[i, 6]))\n",
    "    \n",
    "    energy['Coal Percent'] = coal_percent\n",
    "    energy['Natural Gas Percent'] = natural_gas_percent\n",
    "    energy['Nuclear Percent'] = nuclear_percent\n",
    "    energy['Hydroelectric Percent'] = hydroelectric_percent\n",
    "    energy['Wind Percent'] = wind_percent\n",
    "    energy['Solar Percent'] = solar_percent\n",
    "    \n",
    "    return energy\n",
    "\n",
    "\n",
    "def energy_percent(x):\n",
    "    \n",
    "    energy = pd.DataFrame({'date' : x['date'],\n",
    "                           'Coal Percent' : x['Coal Percent'],\n",
    "                           'Natural Gas Percent' : x['Natural Gas Percent'],\n",
    "                           'Nuclear Percent' : x['Nuclear Percent'],\n",
    "                           'Hydroelectric Percent' : x['Hydroelectric Percent'],\n",
    "                           'Wind' : x['Wind Percent'],\n",
    "                           'Solar' : x['Solar Percent'],\n",
    "                           'Ozone' : x['Annual Ozone'],\n",
    "                           'PM2.5' : x['Annual PM2.5']})\n",
    "\n",
    "    return energy\n",
    "\n",
    "def plot_energy(x, y):\n",
    "    fig, ax1 = plt.subplots(figsize=(16, 10))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(x['date'], x['Coal Percent'], alpha = 0.5)\n",
    "    ax1.plot(x['date'], x['Natural Gas Percent'], alpha = 0.5)\n",
    "    ax1.plot(x['date'], x['Nuclear Percent'], alpha = 0.5)\n",
    "    ax1.plot(x['date'], x['Hydroelectric Percent'], alpha = 0.5)\n",
    "    ax1.plot(x['date'], x['Wind Percent'], alpha = 0.5)\n",
    "    ax1.plot(x['date'], x['Solar Percent'], alpha = 0.5)\n",
    "    ax2.plot(x['date'], x['Annual Ozone'], '--', linewidth = 5)\n",
    "    ax2.plot(x['date'], x['Annual PM2.5'], '--', linewidth = 5)\n",
    "    ax1.set_ylabel('Percentage of Energy')\n",
    "    ax2.set_ylabel('AQI')\n",
    "    ax1.legend(['Coal', 'Natural Gas', 'Nuclear', 'Hydroelectric', 'Wind', 'Solar'], loc = 'upper left')\n",
    "    ax2.legend(['O3', 'PM2.5'], loc = 'upper right')\n",
    "    ax1.set_title(y)\n",
    "    ax1.grid()\n",
    "\n",
    "def pie_energy_2019(x, y):\n",
    "    percentage = [x.iloc[18, 9], x.iloc[18, 10], x.iloc[18, 11], x.iloc[18, 12], x.iloc[18, 13], x.iloc[18, 14]]\n",
    "    df = pd.DataFrame({'date' : x['date'],\n",
    "                       '2020' : percentage},\n",
    "                      index = ['Coal', 'Natural Gas', 'Nuclear',\n",
    "                               'Hydroelectric', 'Wind', 'Solar'])\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.pie(df['2020'], labels = df.index, autopct='%1.0f%%', shadow = True, explode = [.05, .05, .05, .05, .05, .05])\n",
    "    ax.legend(['Coal', 'Natural Gas', 'Nuclear', 'Hydroelectric', 'Wind', 'Solar'], loc = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_data(x, y):\n",
    "    \n",
    "    time = ['1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
    "     '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', \n",
    "     '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013','2014', '2015', '2016', '2017', '2018', \n",
    "     '2019', '2020']\n",
    "    \n",
    "    temp = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Temperature/' + x + '-Temp.csv')\n",
    "    temp = pd.DataFrame({'date' : temp['Date'],\n",
    "                        'Temp' : temp['Value']})\n",
    "    \n",
    "    temp['date'] = pd.to_datetime(time)\n",
    "    temp = temp.dropna()\n",
    "    y['date'] = pd.to_datetime(time)\n",
    "    temp = pd.merge(temp, y, how = 'left', on = 'date')\n",
    "    \n",
    "    return temp\n",
    "\n",
    "def plot_temp(x, y):\n",
    "    fig, ax1 = plt.subplots(figsize = (16, 10))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(x['date'], x['Temp'])\n",
    "    ax2.plot(x['date'], x['Annual Ozone'], '--', linewidth = 5)\n",
    "    ax2.plot(x['date'], x['Annual PM2.5'], '--', linewidth = 5)\n",
    "    ax1.legend(['Temp'], loc = 'upper left')\n",
    "    ax2.legend(['O3', 'PM2.5'], loc = 'upper right')\n",
    "    ax1.set_ylabel('Temperature')\n",
    "    ax2.set_ylabel('AQI')\n",
    "    ax1.set_title(y)\n",
    "    ax1.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing The Data\n",
    "\n",
    "Here we access the file locations for each metropolitan statistical area and use the methods to create dataframes we can work with so we can plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_nj_pa_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/NewYork-Newark-JerseyCity/')\n",
    "ny_nj_pa = rolling_mean(ny_nj_pa_files, 'ozone_aqi')\n",
    "ny_nj_pa = rolling_mean(ny_nj_pa, 'pm25_aqi')\n",
    "ny_nj_pa_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/NY-NJ-PA-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "ny_nj_pa_annual = aqi_annual_average('NewYork-Newark-JerseyCity', 'NY-NJ-PA')\n",
    "ny_nj_pa_production = production_data(ny_nj_pa_production_files, 'NY-NJ-PA', ny_nj_pa_annual)\n",
    "#ny_nj_pa_2020 = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Areas/NewYork-Newark-JerseyCity/2020-NY-NJ-PA.csv')\n",
    "ny_nj_pa_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/NY-NJ-PA-Mobility.csv')\n",
    "ny_nj_pa_mobility = mobility(ny_nj_pa_mobility_files, 'NewYork-Newark-JerseyCity', 'NY-NJ-PA')\n",
    "\n",
    "il_in_wi_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Chicago-Naperville-Elgin/')\n",
    "il_in_wi = rolling_mean(il_in_wi_files, 'ozone_aqi')\n",
    "il_in_wi = rolling_mean(il_in_wi, 'pm25_aqi')\n",
    "il_in_wi_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/IL-IN-WI-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "il_in_wi_annual = aqi_annual_average('Chicago-Naperville-Elgin', 'IL-IN-WI')\n",
    "il_in_wi_production = production_data(il_in_wi_production_files, 'IL-IN-WI', il_in_wi_annual)\n",
    "il_in_wi_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/IL-IN-WI-Mobility.csv')\n",
    "il_in_wi_mobility = mobility(il_in_wi_mobility_files, 'Chicago-Naperville-Elgin', 'IL-IN-WI')\n",
    "\n",
    "tx_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Dallas-FortWorth-Arlington/')\n",
    "tx = rolling_mean(tx_files, 'ozone_aqi')\n",
    "tx = rolling_mean(tx, 'pm25_aqi')\n",
    "tx_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/TX-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "tx_annual = aqi_annual_average('Dallas-FortWorth-Arlington', 'TX')\n",
    "tx_production = production_data(tx_production_files, 'TX', tx_annual)\n",
    "tx_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/TX-Mobility.csv')\n",
    "tx_mobility = mobility(tx_mobility_files, 'Dallas-FortWorth-Arlington', 'TX')\n",
    "\n",
    "ga_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Atlanta-SandySprings-Roswell/')\n",
    "ga = rolling_mean(ga_files, 'ozone_aqi')\n",
    "ga = rolling_mean(ga, 'pm25_aqi')\n",
    "ga_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/GA-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "ga_annual = aqi_annual_average('Atlanta-SandySprings-Roswell', 'GA')\n",
    "ga_production = production_data(ga_production_files, 'GA', ga_annual)\n",
    "ga_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/GA-Mobility.csv')\n",
    "ga_mobility = mobility(ga_mobility_files, 'Atlanta-SandySprings-Roswell', 'GA')\n",
    "\n",
    "ma_nh_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Boston-Cambridge-Newton/')\n",
    "ma_nh = rolling_mean(ma_nh_files, 'ozone_aqi')\n",
    "ma_nh = rolling_mean(ma_nh, 'pm25_aqi')\n",
    "ma_nh_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/MA-NH-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "ma_nh_annual = aqi_annual_average('Boston-Cambridge-Newton', 'MA-NH')\n",
    "ma_nh_production = production_data(ma_nh_production_files, 'MA-NH', ma_nh_annual)\n",
    "ma_nh_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/MA-NH-Mobility.csv')\n",
    "ma_nh_mobility = mobility(ma_nh_mobility_files, 'Boston-Cambridge-Newton', 'MA-NH')\n",
    "\n",
    "mi_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Detroit-Warren-Dearborn/')\n",
    "mi = rolling_mean(mi_files, 'ozone_aqi')\n",
    "mi = rolling_mean(mi, 'pm25_aqi')\n",
    "mi_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/MI-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "mi_annual = aqi_annual_average('Detroit-Warren-Dearborn', 'MI')\n",
    "mi_production = production_data(mi_production_files, 'MI', mi_annual)\n",
    "# year test: mi_2020 = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Detroit-Warren-Dearborn/2020-MI.csv')\n",
    "mi_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/MI-Mobility.csv')\n",
    "mi_mobility = mobility(mi_files, 'Detroit-Warren-Dearborn', 'MI')\n",
    "\n",
    "ca_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/LosAngeles-LongBeach-Anaheim/')\n",
    "ca = rolling_mean(ca_files, 'ozone_aqi')\n",
    "ca = rolling_mean(ca, 'pm25_aqi')\n",
    "ca_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/CA-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "ca_annual = aqi_annual_average('LosAngeles-LongBeach-Anaheim', 'CA')\n",
    "ca_production = production_data(ca_production_files, 'CA', ca_annual)\n",
    "ca_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/CA-Mobility.csv')\n",
    "ca_mobility = mobility(ny_nj_pa_mobility_files, 'LosAngeles-LongBeach-Anaheim', 'CA')\n",
    "\n",
    "fl_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Miami-FortLauderdale-WestPalmBeach/')\n",
    "fl = rolling_mean(fl_files, 'ozone_aqi')\n",
    "fl = rolling_mean(fl, 'pm25_aqi')\n",
    "fl_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/FL-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "fl_annual = aqi_annual_average('Miami-FortLauderdale-WestPalmBeach', 'FL')\n",
    "fl_production = production_data(fl_production_files, 'FL', fl_annual)\n",
    "fl_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/FL-Mobility.csv')\n",
    "fl_mobility = mobility(fl_mobility_files, 'Miami-FortLauderdale-WestPalmBeach', 'FL')\n",
    "\n",
    "pa_nj_de_md_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Philadelphia-Camden-Wilmington/')\n",
    "pa_nj_de_md = rolling_mean(pa_nj_de_md_files, 'ozone_aqi')\n",
    "pa_nj_de_md = rolling_mean(pa_nj_de_md, 'pm25_aqi')\n",
    "pa_nj_de_md_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/PA-NJ-DE-MD-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "pa_nj_de_md_annual = aqi_annual_average('Philadelphia-Camden-Wilmington', 'PA-NJ-DE-MD')\n",
    "pa_nj_de_md_production = production_data(pa_nj_de_md_production_files, 'PA-NJ-DE-MD', pa_nj_de_md_annual)\n",
    "pa_nj_de_md_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/PA-NJ-DE-MD-Mobility.csv')\n",
    "pa_nj_de_md_mobility = mobility(pa_nj_de_md_mobility_files, 'Philadelphia-Camden-Wilmington', 'PA-NJ-DE-MD')\n",
    "\n",
    "az_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Phoenix-Mesa-Scottsdale/')\n",
    "az = rolling_mean(az_files, 'ozone_aqi')\n",
    "az = rolling_mean(az, 'pm25_aqi')\n",
    "az_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/AZ-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "az_annual = aqi_annual_average('Phoenix-Mesa-Scottsdale', 'AZ')\n",
    "az_production = production_data(az_production_files, 'AZ', az_annual)\n",
    "# year test: az_2020 = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Phoenix-Mesa-Scottsdale/2020-AZ.csv')\n",
    "az_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/AZ-Mobility.csv')\n",
    "az_mobility = mobility(az_mobility_files, 'Phoenix-Mesa-Scottsdale', 'AZ')\n",
    "\n",
    "wa_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Seattle-Tacoma-Bellevue/')\n",
    "wa = rolling_mean(wa_files, 'ozone_aqi')\n",
    "wa = rolling_mean(wa, 'pm25_aqi')\n",
    "wa_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/WA-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "wa_annual = aqi_annual_average('Seattle-Tacoma-Bellevue', 'WA')\n",
    "wa_production = production_data(wa_production_files, 'WA', wa_annual)\n",
    "wa_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/WA-Mobility.csv')\n",
    "wa_mobility = mobility(wa_mobility_files, 'Seattle-Tacoma-Bellevue', 'WA')\n",
    "\n",
    "dc_va_md_wv_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Washington-Arlington-Alexandria/')\n",
    "dc_va_md_wv = rolling_mean(dc_va_md_wv_files, 'ozone_aqi')\n",
    "dc_va_md_wv = rolling_mean(dc_va_md_wv, 'pm25_aqi')\n",
    "dc_va_md_wv_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/DC-VA-MD-WV-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "dc_va_md_wv_annual = aqi_annual_average('Washington-Arlington-Alexandria', 'DC-VA-MD-WV')\n",
    "dc_va_md_wv_production = production_data(dc_va_md_wv_production_files, 'DC-VA-MD-WV', dc_va_md_wv_annual)\n",
    "dc_va_md_wv_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/DC-VA-MD-WV-Mobility.csv')\n",
    "dc_va_md_wv_mobility = mobility(dc_va_md_wv_mobility_files, 'Washington-Arlington-Alexandria', 'DC-VA-MD-WV')\n",
    "\n",
    "mn_wi_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Minneapolis-St.Paul-Bloomington/')\n",
    "mn_wi = rolling_mean(mn_wi_files, 'ozone_aqi')\n",
    "mn_wi = rolling_mean(mn_wi, 'pm25_aqi')\n",
    "mn_wi_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/MN-WI-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "mn_wi_annual = aqi_annual_average('Minneapolis-St.Paul-Bloomington', 'MN-WI')\n",
    "mn_wi_production = production_data(mn_wi_production_files, 'MN-WI', mn_wi_annual)\n",
    "mn_wi_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/MN-WI-Mobility.csv')\n",
    "mn_wi_mobility = mobility(mn_wi_mobility_files, 'Minneapolis-St.Paul-Bloomington', 'MN-WI')\n",
    "\n",
    "co_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Denver-Aurora-Lakewood/')\n",
    "co = rolling_mean(co_files, 'ozone_aqi')\n",
    "co = rolling_mean(co, 'pm25_aqi')\n",
    "co_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/CO-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "co_annual = aqi_annual_average('Denver-Aurora-Lakewood', 'CO')   \n",
    "co_production = production_data(co_production_files, 'CO', co_annual)                               \n",
    "# year test: co_2020 = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Areas/Denver-Aurora-Lakewood/2020-CO.csv')\n",
    "co_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/CO-Mobility.csv')\n",
    "co_mobility = mobility(co_mobility_files, 'Denver-Aurora-Lakewood', 'CO')\n",
    "\n",
    "mo_il_files = concatinate('/Users/smaslam/Desktop/airpollution/airpollution/Areas/St.Louis/')\n",
    "mo_il = rolling_mean(mo_il_files, 'ozone_aqi')\n",
    "mo_il = rolling_mean(mo_il, 'pm25_aqi')\n",
    "mo_il_production_files = pd.DataFrame(pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/MO-IL-Production.csv',\n",
    "                                         sep = r'\\s*,\\s*', engine = 'python'))\n",
    "mo_il_annual = aqi_annual_average('St.Louis', 'MO-IL')\n",
    "mo_il_production = production_data(mo_il_production_files, 'MO-IL', mo_il_annual)\n",
    "mo_il_mobility_files = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Mobility/MO-IL-Mobility.csv')\n",
    "mo_il_mobility = mobility(mo_il_mobility_files, 'St.Louis', 'MO-IL')\n",
    "\n",
    "areas = [ny_nj_pa, il_in_wi, tx, ga, ma_nh, mi, ca, fl, pa_nj_de_md, az, wa, dc_va_md_wv, mn_wi, co, mo_il]\n",
    "time = ['2012', '2013', '2014', '2015', '2020']\n",
    "\n",
    "production = [ny_nj_pa_production, il_in_wi_production, tx_production, ga_production, ma_nh_production,\n",
    "              mi_production, ca_production, fl_production, pa_nj_de_md_production, az_production, wa_production,\n",
    "              dc_va_md_wv_production, mn_wi_production, co_production, mo_il_production]\n",
    "\n",
    "production = pd.concat(production)\n",
    "\n",
    "mobility = [ny_nj_pa_mobility, il_in_wi_mobility, tx_mobility, ga_mobility, ma_nh_mobility,\n",
    "              mi_mobility, ca_mobility, fl_mobility, pa_nj_de_md_mobility, az_mobility, wa_mobility,\n",
    "              dc_va_md_wv_mobility, mn_wi_mobility, co_mobility, mo_il_mobility]\n",
    "mobility = pd.concat(mobility)\n",
    "#annual = [ny_nj_pa_annual, il_in_wi_annual, tx_annual, ga_annual, ma_nh_annual, mi_annual, ca_annual,\n",
    "#          fl_annual, pa_nj_de_md_annual, az_annual, wa_annual, dc_va_md_wv_annual, mn_wi_annual, co_annual,\n",
    "#          mo_il_annual]\n",
    "#annual = annual_list(annual, production)\n",
    "#production['O3'] = annual['O3']\n",
    "#production['PM2.5'] = annual['PM2.5']\n",
    "\n",
    "msa = geopandas.read_file('/Users/smaslam/Desktop/airpollution/airpollution/CBSAMap/tl_2019_us_cbsa.shp')\n",
    "msa = msa_drop(msa)\n",
    "us = geopandas.read_file('/Users/smaslam/Desktop/airpollution/airpollution/US/cb_2016_us_state_500k.shp')\n",
    "\n",
    "annual_energy_usage = pd.read_csv('/Users/smaslam/Desktop/airpollution/airpollution/Production/State-Annual-Energy-Usage.csv')\n",
    "annual_energy_usage = annual_energy_usage.sort_values('Year', ascending = True)\n",
    "\n",
    "northeast_production = [ny_nj_pa_production, pa_nj_de_md_production, ma_nh_production, dc_va_md_wv_production]\n",
    "northeast_production = pd.concat(northeast_production)\n",
    "\n",
    "central_production = [mi_production, il_in_wi_production, mo_il_production, mn_wi_production]\n",
    "central_production = pd.concat(central_production)\n",
    "\n",
    "southeast_production = [fl_production, ga_production]\n",
    "southeast_production = pd.concat(southeast_production)\n",
    "\n",
    "southwest_production = [ca_production, tx_production, az_production]\n",
    "southwest_production = pd.concat(southwest_production)\n",
    "\n",
    "outlier_production = [co_production, wa_production]\n",
    "outlier_production = pd.concat(outlier_production)\n",
    "\n",
    "northeast_mobility = [ny_nj_pa_mobility, pa_nj_de_md_mobility, ma_nh_mobility, dc_va_md_wv_mobility]\n",
    "northeast_mobility = pd.concat(northeast_mobility)\n",
    "\n",
    "central_mobility = [mi_mobility, il_in_wi_mobility, mo_il_mobility, mn_wi_mobility]\n",
    "central_mobility = pd.concat(central_mobility)\n",
    "\n",
    "southeast_mobility = [fl_mobility, ga_mobility]\n",
    "southeast_mobility = pd.concat(southeast_mobility)\n",
    "\n",
    "southwest_mobility = [ca_mobility, tx_mobility, az_mobility]\n",
    "southwest_mobility = pd.concat(southwest_mobility)\n",
    "\n",
    "outlier_mobility = [co_mobility, wa_mobility]\n",
    "outlier_mobility = pd.concat(outlier_mobility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_nj_pa_gdp = gdp_production('New York-Newark-Jersey City, NY-NJ-PA (Metropolitan Statistical Area)', ny_nj_pa_annual)\n",
    "ga_gdp = gdp_production('Atlanta-Sandy Springs-Alpharetta, GA (Metropolitan Statistical Area)', ga_annual)\n",
    "ma_nh_gdp = gdp_production('Boston-Cambridge-Newton, MA-NH (Metropolitan Statistical Area)', ma_nh_annual)\n",
    "tx_gdp = gdp_production('Dallas-Fort Worth-Arlington, TX (Metropolitan Statistical Area)', tx_annual)\n",
    "fl_gdp = gdp_production('Miami-Fort Lauderdale-Pompano Beach, FL (Metropolitan Statistical Area)', fl_annual)\n",
    "mn_wi_gdp = gdp_production('Minneapolis-St. Paul-Bloomington, MN-WI (Metropolitan Statistical Area)', mn_wi_annual)\n",
    "pa_nj_de_md_gdp = gdp_production('Philadelphia-Camden-Wilmington, PA-NJ-DE-MD (Metropolitan Statistical Area)', pa_nj_de_md_annual)\n",
    "az_gdp = gdp_production('Phoenix-Mesa-Chandler, AZ (Metropolitan Statistical Area)', az_annual)\n",
    "mo_il_gdp = gdp_production('St. Louis, MO-IL (Metropolitan Statistical Area)', mo_il_annual)\n",
    "wa_gdp = gdp_production('Seattle-Tacoma-Bellevue, WA (Metropolitan Statistical Area)', wa_annual)\n",
    "mi_gdp = gdp_production('Detroit-Warren-Dearborn, MI (Metropolitan Statistical Area)', mi_annual)\n",
    "co_gdp = gdp_production('Denver-Aurora-Lakewood, CO (Metropolitan Statistical Area) *', co_annual)\n",
    "il_in_wi_gdp = gdp_production('Chicago-Naperville-Elgin, IL-IN-WI (Metropolitan Statistical Area)', il_in_wi_annual)\n",
    "ca_gdp = gdp_production('Los Angeles-Long Beach-Anaheim, CA (Metropolitan Statistical Area)', ca_annual)\n",
    "dc_va_md_wv_gdp = gdp_production('Washington-Arlington-Alexandria, DC-VA-MD-WV (Metropolitan Statistical Area) *', dc_va_md_wv_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_energy = energy(annual_energy_usage, ny_nj_pa_annual, 'NY')\n",
    "nj_energy = energy(annual_energy_usage, ny_nj_pa_annual, 'NJ')\n",
    "pa_ny_energy = energy(annual_energy_usage, ny_nj_pa_annual, 'PA')\n",
    "ga_energy = energy(annual_energy_usage, ga_annual, 'GA')\n",
    "ma_energy = energy(annual_energy_usage, ma_nh_annual, 'MA')\n",
    "nh_energy = energy(annual_energy_usage, ma_nh_annual, 'NH')\n",
    "tx_energy = energy(annual_energy_usage, tx_annual, 'TX')\n",
    "mn_energy = energy(annual_energy_usage, mn_wi_annual, 'MN')\n",
    "wi_mn_energy = energy(annual_energy_usage, mn_wi_annual, 'WI')\n",
    "pa_pa_energy = energy(annual_energy_usage, pa_nj_de_md_annual, 'PA')\n",
    "nj_pa_energy = energy(annual_energy_usage, pa_nj_de_md_annual, 'NJ')\n",
    "de_energy = energy(annual_energy_usage, pa_nj_de_md_annual, 'DE')\n",
    "md_pa_energy = energy(annual_energy_usage, pa_nj_de_md_annual, 'MD')\n",
    "mo_energy = energy(annual_energy_usage, mo_il_annual, 'MO')\n",
    "il_mo_energy = energy(annual_energy_usage, mo_il_annual, 'IL')\n",
    "fl_energy = energy(annual_energy_usage, fl_annual, 'FL')\n",
    "ca_energy = energy(annual_energy_usage, ca_annual, 'CA')\n",
    "az_energy = energy(annual_energy_usage, az_annual, 'AZ')\n",
    "wa_energy = energy(annual_energy_usage, wa_annual, 'WA')\n",
    "mi_energy = energy(annual_energy_usage, mi_annual, 'MI')\n",
    "co_energy = energy(annual_energy_usage, co_annual, 'CO')\n",
    "il_in_energy = energy(annual_energy_usage, il_in_wi_annual, 'IL')\n",
    "in_energy = energy(annual_energy_usage, il_in_wi_annual, 'MD')\n",
    "wi_in_energy = energy(annual_energy_usage, il_in_wi_annual, 'WI')\n",
    "va_energy = energy(annual_energy_usage, dc_va_md_wv_annual, 'VA')\n",
    "wv_energy = energy(annual_energy_usage, dc_va_md_wv_annual, 'WV')\n",
    "md_dc_energy = energy(annual_energy_usage, dc_va_md_wv_annual, 'MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ny_temp = temp_data('NY', ny_nj_pa_annual)\n",
    "nj_temp = temp_data('NJ', ny_nj_pa_annual)\n",
    "pa_ny_temp = temp_data('PA', ny_nj_pa_annual)\n",
    "ga_temp = temp_data('GA', ga_annual)\n",
    "ma_temp = temp_data('MA', ma_nh_annual)\n",
    "nh_temp = temp_data('NH', ma_nh_annual)\n",
    "tx_temp = temp_data('TX', tx_annual)\n",
    "mn_temp = temp_data('MN', mn_wi_annual)\n",
    "wi_mn_temp = temp_data('WI', mn_wi_annual)\n",
    "pa_pa_temp = temp_data('PA', pa_nj_de_md_annual)\n",
    "nj_pa_temp = temp_data('NJ', pa_nj_de_md_annual)\n",
    "de_temp = temp_data('DE', pa_nj_de_md_annual)\n",
    "md_pa_temp = temp_data('MD', pa_nj_de_md_annual)\n",
    "mo_temp = temp_data('MO', mo_il_annual)\n",
    "il_mo_temp = temp_data('IL', mo_il_annual)\n",
    "fl_temp = temp_data('FL', fl_annual)\n",
    "ca_temp = temp_data('CA', ca_annual)\n",
    "az_temp = temp_data('AZ', az_annual)\n",
    "wa_temp = temp_data('WA', wa_annual)\n",
    "mi_temp = temp_data('MI', mi_annual)\n",
    "co_temp = temp_data('CO', co_annual)\n",
    "il_in_temp = temp_data('IL', il_in_wi_annual)\n",
    "in_temp = temp_data('IN', il_in_wi_annual)\n",
    "wi_in_temp = temp_data('WI', il_in_wi_annual)\n",
    "va_wv_temp = temp_data('VA', dc_va_md_wv_annual)\n",
    "md_dc_temp = temp_data('MD', dc_va_md_wv_annual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
